{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Identify creative dishes: Sushi & Sandwiches  (all code version) <a class=\"tocSkip\">\n",
        "    \n",
        "**Deep Learning assignment with public available data** \n",
        "\n",
        "\n",
        "Angel Martinez-Tenor \n",
        "    \n",
        "September 2018 (Last Updated in May 2021) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc": true
      },
      "source": [
        "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-the-Data\" data-toc-modified-id=\"Load-the-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Load the Data</a></span></li><li><span><a href=\"#Explore-and-Process-the-Data\" data-toc-modified-id=\"Explore-and-Process-the-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Explore and Process the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Visualize-the-data\" data-toc-modified-id=\"Visualize-the-data-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Visualize the data</a></span></li><li><span><a href=\"#Split-the-data-into-training-and-validation-sets-(not-enough-data-for-3-partitions)\" data-toc-modified-id=\"Split-the-data-into-training-and-validation-sets-(not-enough-data-for-3-partitions)-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Split the data into training and validation sets (not enough data for 3 partitions)</a></span></li><li><span><a href=\"#Create-image-generators-with-data-augmentation\" data-toc-modified-id=\"Create-image-generators-with-data-augmentation-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Create image generators with data augmentation</a></span></li></ul></li><li><span><a href=\"#Build-and-train-the-Neural-Network-model\" data-toc-modified-id=\"Build-and-train-the-Neural-Network-model-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Build and train the Neural Network model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-a-well-known-model-pre-trained-on-Imagenet-dataset-(only-convolutional-layers)\" data-toc-modified-id=\"Load-a-well-known-model-pre-trained-on-Imagenet-dataset-(only-convolutional-layers)-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Load a well-known model pre-trained on Imagenet dataset (only convolutional layers)</a></span></li><li><span><a href=\"#Get-bottleneck-features\" data-toc-modified-id=\"Get-bottleneck-features-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Get bottleneck features</a></span></li><li><span><a href=\"#Build-a-final-fully-connected-classifier\" data-toc-modified-id=\"Build-a-final-fully-connected-classifier-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Build a final fully connected classifier</a></span></li><li><span><a href=\"#Train-the-Classifier-with-the-bottleneck-features\" data-toc-modified-id=\"Train-the-Classifier-with-the-bottleneck-features-1.4.4\"><span class=\"toc-item-num\">1.4.4&nbsp;&nbsp;</span>Train the Classifier with the bottleneck features</a></span></li></ul></li><li><span><a href=\"#Build-the-full-model-(pre-trained-bottleneck-+-custom-classifier)\" data-toc-modified-id=\"Build-the-full-model-(pre-trained-bottleneck-+-custom-classifier)-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Build the full model (pre-trained bottleneck + custom classifier)</a></span></li><li><span><a href=\"#Make-Predictions-and-get-Results\" data-toc-modified-id=\"Make-Predictions-and-get-Results-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Make Predictions and get Results</a></span></li><li><span><a href=\"#Analysis-of-results-and-&amp;-Future-work\" data-toc-modified-id=\"Analysis-of-results-and-&amp;-Future-work-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Analysis of results and &amp; Future work</a></span></li></ul></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Description\n",
        "\n",
        "<b>Goal:</b> Identify samples that could potentially be considered as a combination of two dishes given their pictures\n",
        "\n",
        "<b> Input: </b> Two separated folders with pictures of each class. The example provided here uses a dataset with 402 pictures of sandwiches and 402 pictures of sushi. [Link](http://research.us-east-1.s3.amazonaws.com/public/sushi_or_sandwich_photos.zip)\n",
        "\n",
        "Only the best model obtained is shown here: MobileNet with input size (224,224) pre-trained with Imagenet with a small fully connected classified trained and tuned with this data.\n",
        "\n",
        "This implementation is largely influenced and reuses code from the following sources:\n",
        "\n",
        "- [Francois Chollet: 'Building powerful image classification models using very little data'](https://blog.tensorflow.keras.io/building-powerful-image-classification-models-using-very-little-data.html)  (main guide)\n",
        "\n",
        "- [Bharat Kunwar: 'Sushi or Sandwich classifier'](https://github.com/brtknr/SushiSandwichClassifier/blob/master/sushi-or-sandwich-tensorflow.keras.ipynb) (base classifier)\n",
        "\n",
        "- [Angel Martinez-Tenor: 'Data science projects with Keras'](https://github.com/angelmtenor/data-science-keras) (setup, structure, and helper functions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:33:36.663775Z",
          "start_time": "2021-05-30T17:33:34.764663Z"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import helper_ml  # custom library for this assignment\n",
        "\n",
        "helper_ml.info_system()\n",
        "sns.set_palette(\"Reds\")\n",
        "helper_ml.reproducible(seed=0)  # setup reproducible results from run to run using Keras\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:33:36.671579Z",
          "start_time": "2021-05-30T17:33:36.666407Z"
        }
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "cloud_path = \"http://research.us-east-1.s3.amazonaws.com/public/sushi_or_sandwich_photos.zip\"\n",
        "data_file = \"sushi_or_sandwich_photos.zip\"\n",
        "data_dir = \"sushi_or_sandwich\"\n",
        "\n",
        "# Download the pictures\n",
        "if not os.path.isfile(data_file):\n",
        "    print(\"Downloading data ...\")\n",
        "    os.system(\"wget \" + cloud_path)\n",
        "    print(\"Downloading data ... OK\\n\")\n",
        "\n",
        "# Extract the pictures\n",
        "if not os.path.isdir(data_dir):\n",
        "    print(\"Extracting data ...\")\n",
        "    zip_ref = zipfile.ZipFile(data_file, \"r\")\n",
        "    zip_ref.extractall(\"./\")\n",
        "    zip_ref.close()\n",
        "    print(\"Extracting data ... OK\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explore and Process the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:33:39.709438Z",
          "start_time": "2021-05-30T17:33:36.674064Z"
        }
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from pylab import gcf\n",
        "\n",
        "\n",
        "def load_samples(path, size):\n",
        "    \"\"\"load and return an array of images\"\"\"\n",
        "    imagesList = os.listdir(path)\n",
        "    samples = []\n",
        "    for image in imagesList[:size]:\n",
        "        img = Image.open(os.path.join(path, image))\n",
        "        samples.append(img)\n",
        "    return samples\n",
        "\n",
        "\n",
        "for c in (\"sandwich\", \"sushi\"):\n",
        "    path = os.path.join(data_dir, c)\n",
        "    imgs = load_samples(path, 18)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    gcf().suptitle(c + \" samples\", fontsize=18)\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        # you can show every image\n",
        "        plt.subplot(3, 6, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "# Print the number of pictures\n",
        "print(\"pictures:\")\n",
        "for c in (\"sandwich\", \"sushi\"):\n",
        "    path = os.path.join(data_dir, c)\n",
        "    print(\n",
        "        \"{}   \\t{}\".format(\n",
        "            c,\n",
        "            len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))]),\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Split the data into training and validation sets (not enough data for 3 partitions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:33:39.870251Z",
          "start_time": "2021-05-30T17:33:39.710702Z"
        }
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import glob\n",
        "\n",
        "val_size = 0.3  # size the of validation set\n",
        "train_dir = \"train\"\n",
        "val_dir = \"validation\"\n",
        "\n",
        "# remove existing sets\n",
        "for d in (train_dir, val_dir):\n",
        "    if os.path.isdir(d):\n",
        "        shutil.rmtree(d)\n",
        "        print(\"old \" + d + \" directory deleted\")\n",
        "    # create empty directories\n",
        "    for c in (\"sandwich\", \"sushi\"):\n",
        "        os.makedirs(os.path.join(d, c))\n",
        "    print(\"empty \" + d + \" directory created\")\n",
        "\n",
        "# Create training and validation sets\n",
        "for c in (\"sandwich\", \"sushi\"):\n",
        "    files = glob.glob(\"{}/{}/*.jpg\".format(data_dir, c))\n",
        "    indices = np.random.permutation(len(files))\n",
        "    train_val_split = int(len(files) * (val_size))\n",
        "    for i, ix in enumerate(indices):\n",
        "        src = files[ix]\n",
        "        dest = \"{}/{}/{}\".format(val_dir if i < train_val_split else train_dir, c, files[ix].split(\"/\")[-1])\n",
        "        shutil.copyfile(src, dest)\n",
        "\n",
        "# Print the number of pictures in each set\n",
        "print(\"\\npictures:\")\n",
        "for d in (train_dir, val_dir):\n",
        "    for c in (\"sandwich\", \"sushi\"):\n",
        "        path = os.path.join(d, c)\n",
        "        print(\n",
        "            \"{} {}  {}\".format(\n",
        "                d,\n",
        "                c,\n",
        "                len([n for n in os.listdir(path) if os.path.isfile(os.path.join(path, n))]),\n",
        "            )\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create image generators with data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:33:39.876513Z",
          "start_time": "2021-05-30T17:33:39.871783Z"
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.4,  # high change of perspective in this pictures\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1 / 255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and train the Neural Network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load a well-known model pre-trained on Imagenet dataset (only convolutional layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:35:04.043432Z",
          "start_time": "2021-05-30T17:35:03.618703Z"
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "\n",
        "model_bottleneck = MobileNet(weights=\"imagenet\", include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "for layer in model_bottleneck.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get bottleneck features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:35:24.023778Z",
          "start_time": "2021-05-30T17:35:05.838112Z"
        }
      },
      "outputs": [],
      "source": [
        "print(\"Image generation:\")\n",
        "train_bottleneck_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "val_bottleneck_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "train_bottleneck = model_bottleneck.predict(train_bottleneck_generator, verbose=1)\n",
        "val_bottleneck = model_bottleneck.predict(val_bottleneck_generator, verbose=1)\n",
        "train_labels = train_bottleneck_generator.classes\n",
        "val_labels = val_bottleneck_generator.classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build a final fully connected classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:36:02.382573Z",
          "start_time": "2021-05-30T17:36:02.311447Z"
        }
      },
      "outputs": [],
      "source": [
        "model = None\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Dense,\n",
        "    MaxPooling2D,\n",
        "    Conv2D,\n",
        "    InputLayer,\n",
        "    Activation,\n",
        ")\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "def build_top_nn(summary=False):\n",
        "\n",
        "    w = TruncatedNormal(mean=0.0, stddev=0.0001, seed=None)\n",
        "    opt = Adamax(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "\n",
        "    model_top = Sequential()\n",
        "    model_top.add(Flatten(input_shape=train_bottleneck.shape[1:]))\n",
        "    model_top.add(Dense(16, kernel_initializer=w, bias_initializer=\"zeros\"))\n",
        "    model_top.add(Activation(\"relu\"))\n",
        "    model_top.add(Dropout(0.5))\n",
        "    model_top.add(Dense(1, kernel_initializer=w, bias_initializer=\"zeros\"))\n",
        "    model_top.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    if summary:\n",
        "        model_top.summary()\n",
        "\n",
        "    model_top.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model_top\n",
        "\n",
        "\n",
        "model_top = build_top_nn(summary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the Classifier with the bottleneck features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:37:04.243202Z",
          "start_time": "2021-05-30T17:36:45.229687Z"
        }
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# tuned hyper-parameters\n",
        "# batch_size = batch size for generators (above)\n",
        "patience = 50\n",
        "nb_epoch = 500\n",
        "\n",
        "\n",
        "def train_nn(model, show=True):\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        \"checkpoint-top.h5\",\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        mode=\"auto\",\n",
        "    )\n",
        "\n",
        "    early = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=patience, verbose=0, mode=\"auto\")\n",
        "\n",
        "    if show:\n",
        "        print(\"Training ....\")\n",
        "        t0 = time()\n",
        "\n",
        "    history = model.fit(\n",
        "        train_bottleneck,\n",
        "        train_labels,\n",
        "        epochs=nb_epoch,\n",
        "        batch_size=batch_size,\n",
        "        verbose=0,\n",
        "        validation_data=(val_bottleneck, val_labels),\n",
        "        callbacks=[checkpoint, early],\n",
        "    )\n",
        "\n",
        "    if show:\n",
        "        print(\"time: \\t {:.1f} s\".format(time() - t0))\n",
        "        helper_ml.show_training(history)\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "model_top = None\n",
        "model_top = build_top_nn(summary=False)\n",
        "history = train_nn(model_top)\n",
        "\n",
        "# restore best model found (callback-checkpoint)\n",
        "model_top = None\n",
        "model_top = load_model(\"checkpoint-top.h5\")\n",
        "\n",
        "acc = model_top.evaluate(val_bottleneck, val_labels, verbose=0)[1]\n",
        "print(\"\\nBest model. Validation accuracy: \\t {:.3f}\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build the full model (pre-trained bottleneck + custom classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:37:04.280566Z",
          "start_time": "2021-05-30T17:37:04.244883Z"
        }
      },
      "outputs": [],
      "source": [
        "# Stack Layers using Keras's functional approach:\n",
        "full_model = Model(inputs=model_bottleneck.input, outputs=model_top(model_bottleneck.output))\n",
        "full_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make Predictions and get Results\n",
        "\n",
        "Potential Dishes = pictures misclassified or with output (sigmoid) $\\in$ (0.45, 0.55). Only the validation set is used here to avoid trained samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-30T17:37:14.419482Z",
          "start_time": "2021-05-30T17:37:04.282769Z"
        }
      },
      "outputs": [],
      "source": [
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"binary\",\n",
        ")\n",
        "\n",
        "plt.rcParams.update({\"figure.max_open_warning\": 0})\n",
        "\n",
        "output_dir = \"output\"\n",
        "\n",
        "if os.path.isdir(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "os.makedirs(output_dir)\n",
        "\n",
        "print(\"Potential Sushi-Sandwiches found:\")\n",
        "\n",
        "n = 0\n",
        "for i in range(len(val_generator)):\n",
        "    images, labels = val_generator[i]\n",
        "    predictions = full_model.predict(images)\n",
        "\n",
        "    for im, l, p in zip(images, labels, predictions.flatten()):\n",
        "        # if (p > 0.45 and p < 0.55):\n",
        "        if (p > 0.45 and p < 0.55) or (l < 0.5 and p > 0.5) or (l > 0.5 and p < 0.5):\n",
        "            n = n + 1\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(im)\n",
        "            plt.axis(\"off\")\n",
        "            plt.savefig(\"{}/{}.jpg\".format(output_dir, n))\n",
        "print(\"{} files saved in '/{}'\".format(n, output_dir))\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of results and & Future work\n",
        "\n",
        "The best model obtained, based on transfer learning with a pre-trained MobileNet, achieved accuracies between 89-92% on the validation set. Less than 80% of accuracy was obtained with smaller custom convolutional models without transfer learning.\n",
        "\n",
        "The generator of the augmented images used to train the classifier is based on the fact that the dishes are usually centered and photographed from different angles.\n",
        "\n",
        "The identified potential dishes contain both actual potential combination and no combination at all. New potential dishes can be obtained by changing the 'SEED' parameter in the main script (different validation set).\n",
        "\n",
        "Better accuracies of the classifier can be obtained by training with a large dataset or by fine-tuning the top layers of the pre-trained MobileNet network. However, it is likely that the identification of potential dishes does not improve. \n",
        "\n",
        "Alternate advanced methods could include Style Transfer or using Generative Adversarial Networks for combining data, as [RemixNet](https://ieeexplore.ieee.org/document/7889574)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 ('potential-dishes')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "vscode": {
      "interpreter": {
        "hash": "fa91da45ab33ea675abe892dad173c89d8b8a8dbfc839ad50358d8e0754634fa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
