{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Assignment: Combining two dishes\n",
    "\n",
    "Ángel Martínez-Tenor. September 25, 2018\n",
    "\n",
    "Goal: Get samples that could potentially be considered as a combination of Sandwich and Sushi\n",
    "\n",
    "Input: 2 separated folders with 402 pictures of sandwiches and 402 pictures of sushi\n",
    "\n",
    "Methodology: Build, train and validate several custom and pretrained convolutional networks. Select the best model (highest validation accuracy) and display potential combinations: those misclassified or with output (sigmoid)  ∈  (0.45, 0.55).\n",
    "\n",
    "Only the best model obtained is shown here: MobileNet with input size (224,224) pretrained with imagenet with a small fully connected classified trained and tuned for the input dataset.\n",
    "\n",
    "\n",
    "This implementation is largely influenced and reuses code from the following sources:\n",
    "\n",
    "- [Francois Chollet: 'Building powerful image classification models using very little data'](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)  (main guide)\n",
    "\n",
    "- [Bharat Kunwar: 'Sushi or Sandwich classifier'](https://github.com/brtknr/SushiSandwichClassifier/blob/master/sushi-or-sandwich-keras.ipynb) (base classifier)\n",
    "\n",
    "- [Angel Martínez-Tenor: 'Data science projects with Keras'](https://github.com/angelmtenor/data-science-keras) (setup, structure, and helper functions)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import helper  # custom library for this assigment\n",
    "\n",
    "helper.info_gpu()\n",
    "sns.set_palette(\"Reds\")\n",
    "helper.reproducible(seed=0)  # setup reproducible results from run to run using Keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "cloud_path = 'http://research.us-east-1.s3.amazonaws.com/public/sushi_or_sandwich_photos.zip'\n",
    "data_file = 'sushi_or_sandwich_photos.zip'\n",
    "data_dir = \"sushi_or_sandwich\"\n",
    "\n",
    "# Download the pictures\n",
    "if not os.path.isfile(data_file):\n",
    "    print('Downloading data ...')\n",
    "    os.system('wget ' + cloud_path)\n",
    "    print('Downloading data ... OK\\n')\n",
    "\n",
    "# Extract the pictures\n",
    "if not os.path.isdir(data_dir):\n",
    "    print('Extracting data ...')\n",
    "    zip_ref = zipfile.ZipFile(data_file, 'r')\n",
    "    zip_ref.extractall('./')\n",
    "    zip_ref.close()\n",
    "    print('Extracting data ... OK\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore and Process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pylab import gcf\n",
    "\n",
    "\n",
    "def load_samples(path, size):\n",
    "    \"\"\" load and return an array of images \"\"\"\n",
    "    imagesList = os.listdir(path)\n",
    "    samples = []\n",
    "    for image in imagesList[:size]:\n",
    "        img = Image.open(os.path.join(path, image))\n",
    "        samples.append(img)\n",
    "    return samples\n",
    "\n",
    "\n",
    "for c in ('sandwich', 'sushi'):\n",
    "    path = os.path.join(data_dir, c)\n",
    "    imgs = load_samples(path, 18)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    gcf().suptitle(c + \" samples\", fontsize=18)\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "        # you can show every image\n",
    "        plt.subplot(3, 6, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "# Print the number of pictures\n",
    "print(\"pictures:\")\n",
    "for c in ('sandwich', 'sushi'):\n",
    "    path = os.path.join(data_dir, c)\n",
    "    print(\"{}   \\t{}\".format(\n",
    "        c, len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split the data into training and validation sets (not enough data for 3 partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import glob\n",
    "\n",
    "val_size = 0.3 # size the of validation set\n",
    "train_dir = \"train\"\n",
    "val_dir = \"validation\"\n",
    "\n",
    "# remove existing sets\n",
    "for d in (train_dir, val_dir):\n",
    "    if os.path.isdir(d):\n",
    "        shutil.rmtree(d)\n",
    "        print('old ' + d + ' directory deleted')\n",
    "    # create empty directories\n",
    "    for c in ('sandwich', 'sushi'):\n",
    "        os.makedirs(os.path.join(d, c))\n",
    "    print('empty ' + d + ' directory created')\n",
    "\n",
    "# Create training and validation sets\n",
    "for c in ('sandwich', 'sushi'):\n",
    "    files = glob.glob('{}/{}/*.jpg'.format(data_dir, c))\n",
    "    indices = np.random.permutation(len(files))\n",
    "    train_val_split = int(len(files) * (val_size))\n",
    "    for i, ix in enumerate(indices):\n",
    "        src = files[ix]\n",
    "        dest = '{}/{}/{}'.format(val_dir if i < train_val_split else train_dir, c,\n",
    "                                 files[ix].split('/')[-1])\n",
    "        shutil.copyfile(src, dest)\n",
    "\n",
    "# Print the number of pictures in each set\n",
    "print(\"\\npictures:\")\n",
    "for d in (train_dir, val_dir):\n",
    "    for c in ('sandwich', 'sushi'):\n",
    "        path = os.path.join(d, c)\n",
    "        print(\"{} {}  {}\".format(\n",
    "            d, c, len([n for n in os.listdir(path) if os.path.isfile(os.path.join(path, n))])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create image generators with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.4,  # high change of persperctive in this pictures\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "print('Image generators:')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build and train the Neural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a well-known model pretrained on Imagenet dataset (only convolutional layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bottleneck = keras.applications.MobileNet(\n",
    "    weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "for layer in model_bottleneck.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "train_bottleneck_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    color_mode='rgb',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "val_bottleneck_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    color_mode='rgb',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "train_bottleneck = model_bottleneck.predict_generator(train_bottleneck_generator, verbose=1)\n",
    "val_bottleneck = model_bottleneck.predict_generator(val_bottleneck_generator, verbose=1)\n",
    "train_labels = train_generator.classes\n",
    "val_labels = val_generator.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biuld a final fully connected classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, MaxPooling2D, Conv2D, InputLayer, Activation\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "def build_top_nn(summary=False):\n",
    "\n",
    "    w = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.0001, seed=None)\n",
    "    opt = keras.optimizers.Adamax(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "\n",
    "    model_top = Sequential()\n",
    "    model_top.add(Flatten(input_shape=train_bottleneck.shape[1:]))\n",
    "    model_top.add(Dense(16, kernel_initializer=w, bias_initializer='zeros'))\n",
    "    model_top.add(Activation('relu'))\n",
    "    model_top.add(Dropout(0.5))\n",
    "    model_top.add(Dense(1, kernel_initializer=w, bias_initializer='zeros'))\n",
    "    model_top.add(Activation('sigmoid'))\n",
    "\n",
    "    if summary:\n",
    "        model_top.summary()\n",
    "\n",
    "    model_top.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_top\n",
    "\n",
    "\n",
    "model_top = build_top_nn(summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Classifier with the bottleneck features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# tuned hyperparameters\n",
    "batch_size = 32\n",
    "patience = 50\n",
    "nb_epoch = 500\n",
    "\n",
    "\n",
    "def train_nn(model, show=True):\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        \"checkpoint-top.h5\",\n",
    "        monitor='val_acc',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        period=1)\n",
    "\n",
    "    early = EarlyStopping(\n",
    "        monitor='val_acc', min_delta=0, patience=patience, verbose=0, mode='auto')\n",
    "\n",
    "    if show:\n",
    "        print('Training ....')\n",
    "        t0 = time()\n",
    "\n",
    "    history = model_top.fit(\n",
    "        train_bottleneck,\n",
    "        train_labels,\n",
    "        epochs=nb_epoch,\n",
    "        batch_size=batch_size,\n",
    "        verbose=0,\n",
    "        validation_data=(val_bottleneck, val_labels),\n",
    "        callbacks=[checkpoint, early])\n",
    "\n",
    "    if show:\n",
    "        print(\"time: \\t {:.1f} s\".format(time() - t0))\n",
    "        helper.show_training(history)\n",
    "\n",
    "\n",
    "model_top = None\n",
    "model_top = build_top_nn(summary=False)\n",
    "train_nn(model_top)\n",
    "\n",
    "# restore best model found (callback-checkpoint)\n",
    "model_top = None\n",
    "model_top = keras.models.load_model(\"checkpoint-top.h5\")\n",
    "\n",
    "acc = model_top.evaluate(val_bottleneck, val_labels, verbose=0)[1]\n",
    "print('\\nBest model. Validation accuracy: \\t {:.3f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the full model (pretrained bottleneck + custom classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stack Layers using Keras's fucntional approach:\n",
    "full_model = Model(inputs=model_bottleneck.input, outputs=model_top(model_bottleneck.output))\n",
    "full_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make Predictions and get Results\n",
    "\n",
    "### Show and save potential dishes: pictures misclassified or with output (sigmoid) $\\in$ (0.45, 0.55). Only the validation set is used here to avoid trained samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "output_dir = \"output\"\n",
    "\n",
    "if os.path.isdir(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "os.makedirs(output_dir)\n",
    "\n",
    "print(\"Ideas for combining Sandwich and Sushi:\")\n",
    "\n",
    "n = 0\n",
    "for i in range(len(val_generator)):\n",
    "    images, labels = val_generator[i]\n",
    "    predictions = full_model.predict(images)\n",
    "\n",
    "    for im, l, p in zip(images, labels, predictions.flatten()):\n",
    "        #if (p > 0.45 and p < 0.55):\n",
    "        if (p > 0.45 and p < 0.55) or (l < 0.5 and p > 0.5) or (l > 0.5 and p < 0.5):\n",
    "            n = n + 1\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(im)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(\"{}/{}.jpg\".format(output_dir, n))\n",
    "print(\"{} files saves in '/{}'\".format(n, output_dir))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# original_train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# original_train_generator = original_train_datagen.flow_from_directory(\n",
    "#     train_dir,\n",
    "#     target_size=(img_height, img_width),\n",
    "#     batch_size=batch_size,\n",
    "#     class_mode=\"binary\",\n",
    "# )\n",
    "\n",
    "# print(\"\\nMixed Predictions from the training set:\")\n",
    "\n",
    "# for i in range(len(original_train_generator)):\n",
    "#     images, labels = original_train_generator[i]\n",
    "#     predictions = full_model.predict(images)\n",
    "\n",
    "#     for ix, (im, l, p) in enumerate(zip(images, labels, predictions.flatten())):\n",
    "#         if (p > 0.45 and p < 0.55) or (l<0.5 and p>0.5) or (l>0.5 and p<0.5):\n",
    "#             plt.figure(figsize=(6, 6))\n",
    "#             plt.imshow(im)\n",
    "#             plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
